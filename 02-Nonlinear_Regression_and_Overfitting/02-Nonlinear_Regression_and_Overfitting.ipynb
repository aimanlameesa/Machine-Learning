{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "ID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afb3d0b373f15f5d571a288e593cc641",
     "grade": false,
     "grade_id": "cell-a76a50f786728ccb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Lab 02: Nonlinear Regression and Overfitting\n",
    "\n",
    "In Lab 01, we explored the construction of linear regression models. Recall the assumptions we make in linear regression:\n",
    "- $\\textbf{x} \\in {\\cal X} = \\mathbb{R}^n$\n",
    "- $y \\in {\\cal Y} = \\mathbb{R}$\n",
    "- The $\\textbf{x}$ data are drawn i.i.d. from some (unknown) distribution over ${\\cal X}$\n",
    "- There is a linear relationship between $\\textbf{x}$ and $y$ with additive constant-variance Gaussian noise, i.e., $y \\sim {\\cal N}(\\theta^\\top \\textbf{x}, \\sigma^2)$,\n",
    "  where $\\theta \\in \\mathbb{R}^{n+1}$ is unknown and $\\textbf{x}$ is an $n+1$-dimensional vector augemented with a constant value of 1 as its first element.\n",
    "\n",
    "Today, we consider what we might do when the fourth assumption, linearity, does not hold. We introduce a particular form of nonlinear regression,\n",
    "*polynomial regression*, in which we account for nonlinear relationships between $\\mathbf{x}$ and $y$ by performing nonlinear transformations of\n",
    "the input variables in $\\mathbf{x}$.\n",
    "\n",
    "As an example, if we had a single input variable $x$, linear regression gives us the hypothesis\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x .$$\n",
    "We can add a new \"variable\" $x^2$, which is a nonlinear transformation of the input $x$:\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 .$$\n",
    "The important thing to notice here is that although the hypothesis is *nonlinear* in $x$, allowing us to model a more complex function than\n",
    "ordinary linear regression, the hypothesis is *linear* in $\\theta$, allowing us to use the normal equations to find the optimal $\\theta$ as before.\n",
    "\n",
    "## Polynomial Regression\n",
    "\n",
    "More generally, polynomial regession is a form of linear regression in which the relationship between the independent variables $\\mathbf{x}$ and the dependent\n",
    "variable $y$ is modelled as a polynomial.\n",
    "\n",
    "For a single input $x$, the hypothesis in a polynomial regression of degree $d$ is\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\cdots + \\theta_d x^d$$\n",
    "$$h_\\theta(x) = \\sum_{i=0}^{d} \\theta_i x^i$$\n",
    "\n",
    "For a multivariate input $\\mathbf{x}$, we introduce terms corresponding to every degree-$d$\n",
    "\n",
    "combination of factors. For example, if $n=3$ and $d=2$, we have\n",
    "$$h_\\theta(\\mathbf{x}) = \\theta_0\n",
    "                       + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3\n",
    "                       + \\theta_4 x_1^2 + \\theta_5 x_1 x_2 + \\theta_6 x_1 x_3\n",
    "                       + \\theta_7 x_2^2 + \\theta_8 x_2 x_3 + \\theta_9 x_3^2 .$$\n",
    "\n",
    "## Example 1\n",
    "\n",
    "Let's take a look at how polynomial regression as compared to simple linear regression model works for data with a\n",
    "simple quadratic nonlinearity. First, we generate 100 observations from a ground truth quadratic function with Gaussian noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# please do not change the check result will be wrong\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate X\n",
    "m = 100\n",
    "X = np.random.uniform(-4, 4, (m,1))\n",
    "\n",
    "# Generate y\n",
    "a = 0.7\n",
    "b = 1\n",
    "c = 2\n",
    "y = a * X**2 + b * X + c + np.random.randn(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(X, y, 'b.')\n",
    "plt.title('Polynomial regression example')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4daae127c770ac43f503e93e0ed7261e",
     "grade": false,
     "grade_id": "cell-0ab271629541a02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's use the normal equations to find the $\\theta$ minimizing $J(\\theta)$:\n",
    "$$\\mathbf{\\theta} = (X^\\top X)^{-1}X^\\top\\mathbf{y}$$\n",
    "\n",
    "First, we use ordinary linear regression:\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x$$\n",
    "Then, we use polynomial regression with $d=2$:\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 $$ \n",
    "\n",
    "## Hypothesis Function\n",
    "\n",
    "$$ h_\\mathbf{\\theta}(\\mathbf{x}) = \\mathbf{\\theta}^\\top \\mathbf{x} . $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X, theta):\n",
    "    return X.dot(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e69330d68a379254a2a596aed7e6fbf2",
     "grade": false,
     "grade_id": "cell-8b0f0421e3d03895",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Regression Function\n",
    "\n",
    "The Regression function can be created from normal equation.\n",
    "\n",
    "$$\\mathbf{\\theta} = (X^\\top X)^{-1}X^\\top\\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(X, y):\n",
    "    cov = np.dot(X.T, X)\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    theta = np.dot(cov_inv, np.dot(X.T, y))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9336033bc528413fd998aef5a52b0aee",
     "grade": false,
     "grade_id": "cell-930cc2bd5671cf07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.1 (2 points)\n",
    "\n",
    "Create function RMSE (root mean squared error)\n",
    "$$rms_{error} = \\frac{\\sum_{i=1}^{m} \\left( y^{\\left(i\\right)}-\\hat{y}^\\left(i\\right) \\right)^2}\n",
    "{m}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df95164f7eeee90d2a8ffa6062cf1ff1",
     "grade": false,
     "grade_id": "cell-15468bfde8ba5a54",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    error = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1041aa77d319d4e7b5f69f4b0f99dbb",
     "grade": true,
     "grade_id": "cell-e88c1027c162640f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(rmse(np.array([1,1.1,2,-1]), np.array([1.1,1.3,1.5,0.1])))\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.round(rmse(np.array([1,1.1,2,-0.1]), np.array([1.1,1.3,1.5,0.1])), 5) == np.round(0.29154759474226505, 5), \"calculate rmse incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5095d912cf905c083a8f8e990c7a5773",
     "grade": false,
     "grade_id": "cell-85f320258dae6cee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output:** 0.6144102863722254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b18c9675c4ea0bbad9935cb67ff4084",
     "grade": false,
     "grade_id": "cell-8080fbaa538839fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Simple Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add intercept column of all 1's\n",
    "X_aug = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "# Print first 5 rows of X\n",
    "print(X_aug[0:5,:])\n",
    "\n",
    "# Find optimal parameters\n",
    "theta_slr = regression(X_aug, y)\n",
    "\n",
    "# Predict y\n",
    "y_pred_slr = h(X_aug, theta_slr)\n",
    "\n",
    "print('Linear regression RMSE: %f' % rmse(y, y_pred_slr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "091a5a2ff11be45e529297578b0d9b44",
     "grade": false,
     "grade_id": "cell-57c6d731c3235e74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.2 (2 points)\n",
    "\n",
    "From the simple linear model at above, create another Linear model by using **polynomial model with d=2**.\n",
    " - Create x data in <code>X_aug</code>\n",
    " - Find $\\theta$ and input to <code>theta_pr</code>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint:</b></font></summary>\n",
    "    \n",
    "1. Use <code>np.insert</code> to\n",
    "   - insert **\"$x^{n-1}$\"** when $n$ is number of $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca5f44ed4e32b3fa691b0ec79e588fc0",
     "grade": false,
     "grade_id": "cell-e4d28679467f4ba5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Add constant column and x^2 column\n",
    "X_aug = None\n",
    "# 2. Find optimal parameters \n",
    "theta_pr = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "deac1e15d28bf8901c014e2cae925014",
     "grade": true,
     "grade_id": "cell-e7b5c28a399a58ae",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Predict y \n",
    "y_pred_pr = h(X_aug, theta_pr)\n",
    "print(X_aug[0:5,:])\n",
    "print('Polynomial regression RMSE: %f' % rmse(y, y_pred_pr))\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.array_equal(np.round(theta_pr.T), np.round([[1.90932595, 1.02311816, 0.71747835]])), \"theta_pr are incorrect\"\n",
    "assert np.round(X_aug[10,1] ** 2, 5) == np.round(X_aug[10,2], 5), \"X_aug are incorrect\"\n",
    "assert np.round(rmse(y, y_pred_pr) ** 2 * y.shape[0], 5) == np.round(np.dot((y - y_pred_pr).T, y - y_pred_pr), 5), \"RMSE incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1879f7800f3fa758d99a2b316db2f22b",
     "grade": false,
     "grade_id": "cell-885e8f4444951e38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output** \\\n",
    "[[ 1.          0.39050803  0.15249652]\\\n",
    " [ 1.          1.72151493  2.96361366]\\\n",
    " [ 1.          0.82210701  0.67585993]\\\n",
    " [ 1.          0.35906546  0.12892801]\\\n",
    " [ 1.         -0.61076161  0.37302974]]\\\n",
    "Polynomial regression RMSE: 0.986690"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca4d7b016aa4b86bed9d22b4012a36f4",
     "grade": false,
     "grade_id": "cell-96db0c06cf9f524a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We see that the degree 2 polynomial fit is much better, reducing average error from 3.22 to 0.96.\n",
    "\n",
    "Here's a plot of the predictions vs. observed data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e611b41e16734ab310b6128beea345a",
     "grade": false,
     "grade_id": "cell-dd5029e56cbdcc1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.3 (2 points)\n",
    "\n",
    "Do the **get_prediction function** to predict $\\hat{y}$\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint:</b></font></summary>\n",
    "    \n",
    "1. Use <code>np.insert</code> to\n",
    "   - insert **\"1\"** in front of $x$\n",
    "   - insert **\"$x^{n-1}$\"** when $n$ is number of $\\theta$\n",
    "\n",
    "    \n",
    "2. Use **Hypothesis function** to get $\\hat{y}$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bb48688e4cb8323e790b4d2a4157b91",
     "grade": false,
     "grade_id": "cell-0e66315d337105dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(x, theta):\n",
    "    # Change the shape of x to support the function\n",
    "    x = np.array([x]).T\n",
    "    \n",
    "    y_hat = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff9d67487c494193c55558a27c97d100",
     "grade": true,
     "grade_id": "cell-d0c75741e7ad862c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_series = np.linspace(-4, 4, 1000)\n",
    "y_series_slr = get_predictions(x_series, theta_slr)\n",
    "y_series_pr = get_predictions(x_series, theta_pr)\n",
    "\n",
    "print(\"y_series_slr:\", y_series_slr[2:5].T)\n",
    "print(\"y_series_pr:\", y_series_pr[2:5].T)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.round(get_predictions(np.array([1, 9, 2, -9]), theta_slr).T, 5) is not None, \"predict from theta_slr is incorrect\"\n",
    "assert np.round(get_predictions(np.array([1, 1, 0.1, 2]), theta_pr).T, 5) is not None, \"predict from theta_pr is incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e4fc448f05f9d2a5a9254d0b7934759",
     "grade": false,
     "grade_id": "cell-9a17566e3350d58f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**:\\\n",
    "y_series_slr: [[2.72462183 2.73101513 2.73740842]]\\\n",
    "y_series_pr: [[9.0812643  9.04632656 9.01147497]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7305710d8b87d1fee2d01868d47ef83",
     "grade": false,
     "grade_id": "cell-25ddb38150bdc0d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Plot X, y, and the two regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,0], y, 'c.', label='observations')\n",
    "plt.plot(x_series, y_series_slr, 'b-', label='linear model (d=1)')\n",
    "plt.plot(x_series, y_series_pr, 'r-', label='polynomial model (d=2)')\n",
    "plt.title('Simple linear regression vs. polynomial regression (degree 2)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92232a5c8af5dacde48b9096e416188f",
     "grade": false,
     "grade_id": "cell-79a834611ae2039f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Besides RMSE, let's also get the $R^2$ for our two models. Recall\n",
    "\\begin{align}\n",
    "\\ R^2 = 1 - \\frac{\\sum_{i=1}^{m} \\left( y^{\\left(i\\right)}-\\hat{y}^\\left(i\\right) \\right)^2}\n",
    "{\\sum_{i=1}^{m} \\left( y^{\\left(i\\right)}-\\bar{y}^\\left(i\\right) \\right)^2}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "## Exercise 1.4 (2 points)\n",
    "\n",
    "Create $R^2$ from equation above\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint:</b></font></summary> Use <code>np.square</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d556c1dca720dc813f2b61447a9cff4",
     "grade": false,
     "grade_id": "cell-337cd120daeea8a9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def r_squared(y, y_pred):\n",
    "    r_sqr = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return r_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ff121d755532bb3e6078a97154e5a91",
     "grade": true,
     "grade_id": "cell-535c7f9d800ea951",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Fit of simple linear regression model: %.4f' % r_squared(y, y_pred_slr))\n",
    "print('Fit of polynomial regression model: %.4f' % r_squared(y, y_pred_pr))\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.round(r_squared(np.array([1, 2, 3]), np.array([1, 2, 3]))) == np.round(1.0), \"r_squared is incorrect\"\n",
    "assert np.round(r_squared(y, y_pred_pr), 4) == np.round(0.9353, 4), \"r_squared is incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47b67866524761fb3d795099668f6f5f",
     "grade": false,
     "grade_id": "cell-9adf3f8e5bd7a6cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output:**\\\n",
    "Fit of simple linear regression model: 0.2254\\\n",
    "Fit of polynomial regression model: 0.9353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02d107942871c6a68139d2b1d1491b31",
     "grade": false,
     "grade_id": "cell-c3bc819623aac6ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Another useful analysis is to plot histograms of each model's residuals: \n",
    "\n",
    "## Exercise 1.5 (2 points)\n",
    "\n",
    "Find error of\n",
    " - <code>error_slr</code> is error from simple linear regression\n",
    " - <code>error_pr</code> is error from polynomial linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5b71ca378b3a0b54b3ea2f268d24170",
     "grade": false,
     "grade_id": "cell-d2b59f668e244973",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def residual_error(y, y_pred):\n",
    "    error = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return error\n",
    "\n",
    "error_slr = residual_error(y, y_pred_slr)\n",
    "error_pr = residual_error(y, y_pred_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f99409ffea2d9168188cb0ee8a4098bb",
     "grade": true,
     "grade_id": "cell-b09566ee57735e80",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot distribution of residual error for each model\n",
    "print(\"error_slr sample:\", error_slr[0:5, 0].T)\n",
    "print(\"error_pr sample:\", error_pr[0:5, 0].T)\n",
    "\n",
    "plt.hist(error_slr, bins=10, label = 'Linear')\n",
    "plt.hist(error_pr, bins=10, label = 'Polynomial')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Residual error distribution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.array_equal(np.round(get_predictions(np.array([1, 9, 2, -9]), theta_slr).T),\n",
    "                      np.round([[6.70364883, 13.09055058, 7.50201155, -1.27997835]])), \"predict from theta_slr is incorrect\"\n",
    "assert np.array_equal(np.round(get_predictions(np.array([0, 7, 1.5, -0.3]), theta_pr).T),\n",
    "                      np.round([[2.34050076, 42.14663283, 5.3284002, 2.10566904]])), \"predict from theta_pr is incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f26a2cf6eac501b789ffed9d394fb4b5",
     "grade": false,
     "grade_id": "cell-6f779a2359b39284",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output:**\\\n",
    "error_slr sample: [-4.88494741 -0.58280848 -2.8007543  -5.27887921 -2.27906541]\\\n",
    "error_pr sample: [-1.49521216  0.67105966  0.15715854 -1.86746535  1.14869785]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56515b81544ae89551d64caddd8a9824",
     "grade": false,
     "grade_id": "cell-22d38f90089bbb25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The residual plot shows clearly how much better the polynomial model is than the linear model.\n",
    "\n",
    "## Example 2\n",
    "\n",
    "Next, let's model some monthly sales data from Kaggle using polynomial regression with varying degree.\n",
    "\n",
    "We will observe the effects of varying the degree of the polynomial regression fit on the prediction accuracy.\n",
    "\n",
    "However, as models become more complex, we will encounter the issue of *overfitting*, in which a too-powerful model starts to model the noise in the specific\n",
    "training set rather than the overall trend.\n",
    "\n",
    "To ensure that we're not fitting the noise in the training set, we will split the data into seaparte train and test/validation datasets.\n",
    "The training dataset will consist of 60% of the original observations, and the test dataset will consist of the remaining 40% of the observations.\n",
    "\n",
    "For various polynomial degrees, we'll estimate optimal parameters $\\theta$, then we'll use the test dataset to measure accuracy of the optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV\n",
    "data = np.genfromtxt('MonthlySales_data.csv',delimiter = ',', dtype=str)\n",
    "\n",
    "# Extract headers\n",
    "headers = data[0,:]\n",
    "print(\"Headers:\", headers)\n",
    "\n",
    "# Extract raw data\n",
    "data = np.array(data[1:,:], dtype=float);\n",
    "mean = np.mean(data,axis=0)\n",
    "std = np.std(data,axis=0)\n",
    "data_norm = (data-mean)/std\n",
    "\n",
    "# Extract y column from raw data\n",
    "y_index = np.where(headers == 'sale amount')[0][0];\n",
    "y_data = data[:,y_index];\n",
    "\n",
    "# Extract x column (just the month) from raw data\n",
    "month_index = np.where(headers == 'month')[0][0]\n",
    "# print(year_index, month_index)\n",
    "X_data = data[:,[month_index]];\n",
    "m = X_data.shape[0]\n",
    "n = X_data.shape[1]\n",
    "X_data = X_data.reshape(m, n)\n",
    "\n",
    "print('Extracted %d monthly sales records' % m)\n",
    "print(X_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe28df11dd0fa70fc62afad207a205f2",
     "grade": false,
     "grade_id": "cell-90337e4eafe3ac8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Plot the data\n",
    "\n",
    "Plot 3D by using Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "fig = plt.figure()\n",
    "xx1 =X_data[:,0]\n",
    "zz1 =y_data\n",
    "\n",
    "plt.plot(xx1, zz1, 'b.')\n",
    "plt.xlim(0, 13)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Sales amount')\n",
    "plt.title('Sample monthly sales data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ec213019aed01963e7e121572b2eb68",
     "grade": false,
     "grade_id": "cell-b363fa8e24421d63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.6 (2 points)\n",
    "\n",
    "Partion <code>X_data</code> and <code>y_data</code> into training and test datasets\n",
    " - Do train set as 60% of all data\n",
    " - Other are test set\n",
    " - dataset must be shuffle\n",
    " \n",
    "You can use <link>[random.shuffle](https://www.w3schools.com/python/ref_random_shuffle.asp)</link> to shuffle index of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e28cea4f21ebcccc38c805d3134a49c",
     "grade": false,
     "grade_id": "cell-b7bb05a7472dbde0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "percent_train = .6\n",
    "\n",
    "def partition(X, y, percent_train):\n",
    "    # 1. create index list\n",
    "    idx = np.arange(0,y.shape[0])\n",
    "    random.seed(1412)   # just make sure the shuffle always the same please do not remove\n",
    "    # do yourself follow the instruction\n",
    "    # 2. shuffle index\n",
    "    # 3. Create train/test index\n",
    "    # 4. Separate X_Train, y_train, X_test, y_test\n",
    "    X_train = None\n",
    "    y_train = None\n",
    "    X_test = None\n",
    "    y_test = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return idx, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5892ca109bbe0ee9d7718a20e71e2489",
     "grade": true,
     "grade_id": "cell-da342893c5f9083b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "idx, X_train, y_train, X_test, y_test = partition(X_data, y_data, percent_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(idx[5:9])\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert not np.array_equal(np.round(X_data[0:144, :], 3), np.round(X_train,3)), \"X_train must be shuffled!\"\n",
    "assert not np.array_equal(np.round(X_data[144:, :], 3), np.round(X_test,3)), \"X_test must be shuffled!\"\n",
    "assert not np.array_equal(np.round(y_data[0:144], 3), np.round(y_train,3)), \"y_train must be shuffled!\"\n",
    "assert not np.array_equal(np.round(y_data[144:], 3), np.round(y_test,3)), \"y_test must be shuffled!\"\n",
    "assert np.array_equal(idx[5:9], [26, 75, 51, 162])\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3d555add340dccbac0a34cdb5c4a9c2",
     "grade": false,
     "grade_id": "cell-5a69ef7f6637a7e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output:**\\\n",
    "(144, 1)\\\n",
    "(144,)\\\n",
    "(96, 1)\\\n",
    "(96,)\\\n",
    "[ 26  75  51 162]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2e224075e74244f39315d5d49ba8d7b",
     "grade": false,
     "grade_id": "cell-8e669b7c16801a41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.7 (2 points)\n",
    "\n",
    "Create <code>x_polynomial</code> function\n",
    "$$X=[1, x, x^2, ..., x^{n}]$$\n",
    "\n",
    "when $n$ is number of polynomial set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54787c556190ba365ae110148298c387",
     "grade": false,
     "grade_id": "cell-76860eaedb1e088b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def x_polynomial(x, n):\n",
    "    X = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2211d80f3f0f85cf1962b6706796b97",
     "grade": true,
     "grade_id": "cell-44f06f0709d85512",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(x_polynomial(np.array([[3],[2]]), 5))\n",
    "print(x_polynomial(np.array([[3],[2]]), 5).shape)\n",
    "\n",
    "Xi_train = x_polynomial(X_train, 1)    \n",
    "Xi_test = x_polynomial(X_test, 1)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert x_polynomial(np.array([[2],[3]]), 5).shape[1] == 5 + 1, \"Size of polynomial incorrect\"\n",
    "assert np.array_equal(np.round(x_polynomial(np.array([[2],[3]]), 5), 3), \n",
    "                      np.round([[1, 2, 4, 8, 16, 32], [1, 3, 9, 27, 81, 243]],3)), \"Polynomial are wrong.\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cc0016074c82371bf5fc2a8d0ebd77a",
     "grade": false,
     "grade_id": "cell-9e0e92ebf2cc6b90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output:**\\\n",
    "[[  1.   3.   9.  27.  81. 243.]\\\n",
    " [  1.   2.   4.   8.  16.  32.]]\\\n",
    "(2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18a6f067096a0089ad174bd64dddd857",
     "grade": false,
     "grade_id": "cell-2e817d9ad008f192",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1.8 (2 points)\n",
    "\n",
    "Create <code>cost</code> function ($J$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11584bd3a5fbd7edd0087fcebe2cb7f0",
     "grade": false,
     "grade_id": "cell-c0a1095e6a66f70e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cost(theta,X,y):\n",
    "    J = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7dea0b5d7c046e5888bf6a3d3cbc9e3",
     "grade": true,
     "grade_id": "cell-e7b476298e7765e4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate theta\n",
    "theta = regression(Xi_train, y_train)\n",
    "\n",
    "# calculate cost in train\n",
    "J_train = cost(theta, Xi_train, y_train)\n",
    "\n",
    "y_pred_test = h(Xi_test, theta)\n",
    "J_test = cost(theta, Xi_test, y_test)\n",
    "\n",
    "print(\"J_train:\", J_train)\n",
    "print(\"J_test:\", J_test)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert type(J_train) == np.float64, \"Cost function size must be 1\"\n",
    "assert np.round(J_train, 3) == np.round(174395635.44334993, 3), \"Cost function in train set are wrong\"\n",
    "assert np.round(J_test, 3) == np.round(196382485.91395777, 3), \"Cost function in test set are wrong\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f976663477ef6a255598f907beca38b",
     "grade": false,
     "grade_id": "cell-49f1948f892e79dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output:**\\\n",
    "J_train: 174395635.44334993\\\n",
    "J_test: 196382485.91395777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3fe4fbde6395597ee7ba908f7d64508",
     "grade": false,
     "grade_id": "cell-8e7c6c03b74d9a41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Mixed together\n",
    "\n",
    "Build models of degree 1 to max_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 5\n",
    "\n",
    "J_train = np.zeros(max_degree)\n",
    "J_test = np.zeros(max_degree)\n",
    "\n",
    "# Initalize plots for predictions and loss\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(20)\n",
    "fig.subplots_adjust(left=.2, bottom=None, right=None, top=None, wspace=.2, hspace=.2)\n",
    "plt1 = plt.subplot(1,2,1)\n",
    "plt2 = plt.subplot(1,2,2)\n",
    "plt2.plot(X_train, y_train, 'c.', label='observations')\n",
    "\n",
    "for i in range(1, max_degree+1):\n",
    "    # Fit model on training data and get cost for training and test data\n",
    "    Xi_train = x_polynomial(X_train, i)    \n",
    "    Xi_test = x_polynomial(X_test, i);\n",
    "    theta = regression(Xi_train, y_train)    \n",
    "    J_train[i-1] = cost(theta, Xi_train, y_train)\n",
    "    y_pred_test = h(Xi_test, theta)\n",
    "    J_test[i-1] = cost(theta, Xi_test, y_test)\n",
    "    \n",
    "    # Plot\n",
    "    x_series = np.linspace(0, 13, 1000)\n",
    "    y_series = get_predictions(x_series, theta)\n",
    "    plt2.plot(x_series, y_series, '-', label='degree ' + str(i) + ' (test accuracy ' + str(r_squared(y_test, y_pred_test)) + ')')\n",
    "\n",
    "plt1.plot(np.arange(1, max_degree + 1, 1), J_train, '-', label='train')\n",
    "plt1.plot(np.arange(1, max_degree + 1, 1), J_test, '-', label='test')\n",
    "plt1.set_title('Loss vs polynomial degree')\n",
    "plt1.set_xlabel('polynomial degree')\n",
    "plt1.set_ylabel('loss')\n",
    "plt1.grid(axis='both', alpha=.25)\n",
    "plt1.legend()\n",
    "\n",
    "plt2.set_title('Predicted monthly sales')\n",
    "plt2.set_xlabel('Month')\n",
    "plt2.set_ylabel('Sales ($)')\n",
    "plt2.grid(axis='both', alpha=.25)\n",
    "plt2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d43f4f091a2c34dd0d766c53d485ffaf",
     "grade": false,
     "grade_id": "cell-62fb80f9a7f852e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take some time to undserstand the code. You should see that training loss falls as the degree of the polynomial increases. However, depending on your particular train/test split of the data, you may observe at $d=4$ or $d=5$ that test loss starts to increase. This is the phenomenon of overfitting!\n",
    "\n",
    "If you don't see any evidence of overfitting, you might regenerate the test/train splits (rerun the previous cell as well as the training cell).\n",
    "\n",
    "You may also increase max_degree to a point. However, without normalization of the data, the matrix $\\texttt{X}^\\top\\texttt{X}$ we invert in the solution to the normal equations will become numerically close to singularity, and you will observe unstable solutions. The result is usually a parameter vector $\\theta$ that is suboptimal that gives poor results on both the training set and test set.\n",
    "\n",
    "If you want to evaluate the numerial stability of the correlation matrix $\\texttt{X}^\\top\\texttt{X}$, try this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = Xi_train.T.dot(Xi_train)\n",
    "print('Correlation matrix:', corr)\n",
    "cond = np.linalg.cond(corr)\n",
    "print('Condition number: %0.5g' % cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be4f3a1a0d27e3dabfdf3550a31376ea",
     "grade": false,
     "grade_id": "cell-73b01dfe3d80c217",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Read more about the condition number on <link>[Wikipedia](https://en.wikipedia.org/wiki/Condition_number)</link>. Roughly speaking, if our condition number is $10^k$, we may lose up to $k$ digits of accuracy in the inverse of the matrix. If $k=12$ as above, then we have an extremely poorly conditioned problem, because the IEEE 64 bit floating point representation of reals we're using in Python only has around 16 digits of accuracy (see <link>[Wikipedia's page on IEEE floating point numbers](https://en.wikipedia.org/wiki/IEEE_754)</link>).\n",
    "\n",
    "One way to improve the numerical conditioning of the problem is normalization. If the values of the variable's we're correlating in this matrix have relatively small positive and negative values, the condition number of the correlation matrix will be much smaller and you'll get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbc3a4e56ca3b098755ba98b2cb13166",
     "grade": false,
     "grade_id": "cell-505ec7c2bf4a62e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take some time to undserstand the code. Depending on your random test/train split, you should see that training loss falls as the degree of the polynomial increases.\n",
    "However, you may observe at some point that test loss starts to increase, and you may see some very strange behavior of the model function beyond the range 1-12.\n",
    "If not, go ahead and increase the variable `max_degree` until you see an increase in test loss. This is the phenomenon of overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a46f5b4909760abeccd2b7ff1bbfbef",
     "grade": false,
     "grade_id": "cell-dd696834fab67203",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## In-lab exercise\n",
    "\n",
    "During the lab session, you should perform the following exercises:\n",
    "1. Add the `year` variable from the monthly sales dataset to your simple linear regression model and quantify whether including it improves test set performance. Show\n",
    "   the observations and predictions in a 3D surface plot.\n",
    "2. Develop polynomial regression models of degree 2 and 3 based on the two input variables. Show results as 3D surface plots and discuss whether you observe overfitting\n",
    "   or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acd83ff5271581ed62891be6c7308d60",
     "grade": false,
     "grade_id": "cell-cea5de1c2bd78b4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.1 (2 points)\n",
    "\n",
    "Import **MonthlySales_data.csv** file into <code>data_csv</code> and extract **headers**  at the top of <code>data_csv</code> into <code>headers_csv</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59700ca99935322d12b2c6ce7e59c1bf",
     "grade": false,
     "grade_id": "cell-b43030a1c52e7d4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "headers_csv = None\n",
    "data_csv = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87766378de780066194a97a6ee5e9ab7",
     "grade": true,
     "grade_id": "cell-53eecb55f9059986",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(headers_csv)\n",
    "print(data_csv[:5])\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert type(data_csv[0,0]) == np.float64, \"You must remove the header\"\n",
    "assert headers_csv.shape[0] == 3, \"Headers must have 3 values\"\n",
    "assert type(headers_csv[0]) == np.str_, \"Headers must be string\"\n",
    "assert np.round(data_csv[30, 2], 3) == np.round(2.222027e+04, 3), \"Data is incorrect\"\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1dc8a33da47316d6a1f03edae738416",
     "grade": false,
     "grade_id": "cell-9e0e92ebf2cc6b91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**:\\\n",
    "['year' 'month' 'sale amount']\\\n",
    "[[1.995000e+03 1.000000e+00 1.238611e+04]\\\n",
    " [1.995000e+03 2.000000e+00 1.532923e+04]\\\n",
    " [1.995000e+03 3.000000e+00 5.800217e+04]\\\n",
    " [1.995000e+03 4.000000e+00 5.130520e+04]\\\n",
    " [1.995000e+03 5.000000e+00 1.645247e+04]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08232466173723129d4b78f323024115",
     "grade": false,
     "grade_id": "cell-798a4324eb8f33f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.2 (2 points)\n",
    "\n",
    "- Extract **sale amount** column into <code>y_csv</code>\n",
    "- Extract **year** and **month** columns into <code>X_csv</code> by use **year** at column index 0 and **month** at column index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c961e7d9c73f6fc44a6015a633abd804",
     "grade": false,
     "grade_id": "cell-0e0c8afd2aa3bdd2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Extract y column from raw data\n",
    "# Extract x column (year and month) from raw data\n",
    "y_csv = None\n",
    "X_csv = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91bc14ea7488db7e0bf7e0352adf8b04",
     "grade": true,
     "grade_id": "cell-a15bf28e79e3ff7c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "m = X_csv.shape[0]\n",
    "n = X_csv.shape[1]\n",
    "X_csv = X_csv.reshape(m, n)\n",
    "print('Extracted %d sales records' % m)\n",
    "print('number of x set:', n)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert m == 240, \"Sales records incorrect\"\n",
    "assert n == 2, \"Need to extract 2 columns of X set\"\n",
    "assert np.max(X_csv[:,0]) == 2014 and np.min(X_csv[:,0]) == 1995, \"Year is filled wrong column\"\n",
    "assert np.max(X_csv[:,1]) == 12 and np.min(X_csv[:,1]) == 1, \"Month is filled wrong column \"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8de011c63044293d7c2be7ae96515263",
     "grade": false,
     "grade_id": "cell-e55d4553a54422ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**:\\\n",
    "Extracted 240 sales records\\\n",
    "number of x set: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4af1c1c9ea65acebbfb72873daa1a6f7",
     "grade": false,
     "grade_id": "cell-8a6a8d267c5be8a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.3 (2 points)\n",
    "\n",
    "- Plot 3D graph using <code>mpl_toolkits.mplot3d</code>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint:</b></font></summary>\n",
    "Please see https://matplotlib.org/stable/gallery/mplot3d/scatter3d.html for example\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6010c3490c547eb61e31fbd6088e504b",
     "grade": false,
     "grade_id": "cell-396d4f92e0a00a7f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "# 1. Set plot graph as 3D\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# 2. Extract data\n",
    "# extract year at x-axis\n",
    "# extract month at y-axis\n",
    "# extract sale amount at z-axis\n",
    "x_year = None\n",
    "y_month = None\n",
    "z_sale = None\n",
    "\n",
    "# 3. plot by using scatter\n",
    "\n",
    "# 4. set x, y, z label\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e27203d86ffc1bcee8f71d64e4c78a8",
     "grade": true,
     "grade_id": "cell-7b0eaf5026faac6e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test function: Do not remove\n",
    "assert ax.get_xbound()[1] >= 2014 and ax.get_xbound()[0] <= 1995, \"Year is filled wrong column\"\n",
    "assert ax.get_ybound()[1] >= 12 and ax.get_ybound()[0] <= 1, \"Month is filled wrong column\"\n",
    "assert ax.get_zbound()[1] >= 100000 and ax.get_zbound()[0] <= 0, \"Year is filled wrong column\"\n",
    "assert 'year' in ax.get_xlabel().lower(), \"x-axis label is incorrect\"\n",
    "assert 'month' in ax.get_ylabel().lower(), \"y-axis label is incorrect\"\n",
    "assert 'sale' in ax.get_zlabel().lower(), \"y-axis label is incorrect\"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7180eb5ad33fd3b387cf646fc1d80e3a",
     "grade": false,
     "grade_id": "cell-5966226c4878c809",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output:**\\\n",
    "<img src=\"lab02-01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d7b5a10fb4aea3fef08f89124c3323e",
     "grade": false,
     "grade_id": "cell-7228b4a546408255",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.4 (2 points)\n",
    "\n",
    "Extract data to 60% of training set and 40% of test set with shuffle\n",
    "\n",
    " - You can use <code>partitions</code> function or create your new function and make sure that you must use <code>random.seed(1412)</code> in the code (to make sure that the result will be the same as the expect result)\n",
    " - Please use <code>idx, X_train, y_train, X_test, y_test</code> for the answer result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39cc4725f5edf710eeed230c812907e3",
     "grade": false,
     "grade_id": "cell-146749df078ffcfd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "idx, X_train, y_train, X_test, y_test = None, None, None, None, None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfda602ea828db2faa7afce5b470b84f",
     "grade": true,
     "grade_id": "cell-e18853d209ee0afe",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(idx[5:9])\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert not np.array_equal(np.round(X_csv[0:144, :], 3), np.round(X_train,3)), \"X_train must be shuffled!\"\n",
    "assert not np.array_equal(np.round(X_csv[144:, :], 3), np.round(X_test,3)), \"X_test must be shuffled!\"\n",
    "assert not np.array_equal(np.round(y_csv[0:144], 3), np.round(y_train,3)), \"y_train must be shuffled!\"\n",
    "assert not np.array_equal(np.round(y_csv[144:], 3), np.round(y_test,3)), \"y_test must be shuffled!\"\n",
    "assert np.array_equal(idx[5:9], [26, 75, 51, 162])\n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c4a2d5740239b5d2026917097244e83",
     "grade": false,
     "grade_id": "cell-c5118f9d1f51fda2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**:\\\n",
    "(144, 2)\\\n",
    "(144,)\\\n",
    "(96, 2)\\\n",
    "(96,)\\\n",
    "[ 26  75  51 162]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea6e581962b8a0ccb47271c4de6af4f4",
     "grade": false,
     "grade_id": "cell-371ebc7eb2864a6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.5 (2 points)\n",
    "\n",
    "- Create <code>Xi_train, Xi_Test</code>. X sets must be polynomial of $n=1$.\n",
    "- Calculate <code>theta</code>\n",
    "- Calculate <code>y_pred_test</code>\n",
    "- Calculate cost function $J$ from train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d82afff1c1da3c97e67a83809d93e8d",
     "grade": false,
     "grade_id": "cell-43c618dd04ceb9c8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Xi_train, Xi_test = None, None\n",
    "theta = None\n",
    "y_pred_test = None\n",
    "J_train, J_test = None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf9d8dce7dd9fd801f36a6ff6b40cb82",
     "grade": true,
     "grade_id": "cell-ebaba3da531f0ef0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Xi_train[:3]:\", np.round(Xi_train[:3], 2))\n",
    "print(\"Xi_test[:3]:\", np.round(Xi_test[:3], 2))\n",
    "print(\"theta:\", theta)\n",
    "print(\"y_pred_test[:5]:\", np.round(y_pred_test[:5].T, 2))\n",
    "print(\"J_train:\", J_train)\n",
    "print(\"J_test:\", J_test)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert np.array_equal(np.round(theta, 3), np.round([5.74503812e+05, -2.83158807e+02, 6.37579347e+03],3)), \"Regression theta is incorrect\"\n",
    "assert np.round(J_train, 0) == np.round(172968387.44854635, 0), \"Train cost is incorrect\"\n",
    "assert np.round(J_test, 0) == np.round(204275431.7643744, 0), \"Test cost is incorrect\"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e24db693bc0a4b4b3d9b4c39288a5a0c",
     "grade": false,
     "grade_id": "cell-c710a1b999488f97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**:\\\n",
    "Xi_train[:3]: [[1.000e+00 2.003e+03 1.100e+01]\\\n",
    " [1.000e+00 2.004e+03 3.000e+00]\\\n",
    " [1.000e+00 2.002e+03 6.000e+00]]\\\n",
    "Xi_test[:3]: [[1.000e+00 2.008e+03 1.000e+01]\\\n",
    " [1.000e+00 1.997e+03 5.000e+00]\\\n",
    " [1.000e+00 2.006e+03 1.100e+01]]\\\n",
    "theta: [5.74503812e+05 -2.83158807e+02  6.37579347e+03]\\\n",
    "y_pred_test[:5]: [69678.86 40914.64 76620.97 79169.4  48852.53]\\\n",
    "J_train: 172968387.44854635\\\n",
    "J_test: 204275431.7643744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ea24b07a026f1879c3a299a88ccfa8b",
     "grade": false,
     "grade_id": "cell-7ea805d8d46203af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.6 (2 points)\n",
    "\n",
    "Create **mesh grid point** to plot **surface**\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint:</b></font></summary>\n",
    "Create Mesh grid from numpy.meshgrid (link: https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html)\\\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47b3a6ee7954a04286e29982d96e29a5",
     "grade": false,
     "grade_id": "cell-1d73b15f2ebd57a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Create mesh grid x_mesh, y_mesh\n",
    "#    Hint: this step do in input X dataset only (year, and month series)\n",
    "# 1.1 use numpy.linspace() to generate x_series and y_series\n",
    "#     - do x_series in between min(year) - 1 to max(year) + 1\n",
    "#     - do y_series in between min(month) - 1 to max(month) + 1\n",
    "#     - num_linspace = 100\n",
    "# 1.2 use numpy.meshgrid() to generate x_mesh, and y_mesh\n",
    "# 1.3 merge x_mesh and y_mesh to be xy_mesh\n",
    "num_linspace = 100\n",
    "x_series, y_series = None, None\n",
    "x_mesh, y_mesh, xy_mesh = None, None, None\n",
    "\n",
    "# 2. predict output from xy_mesh to be z_series\n",
    "#    Hint: use mesh_predictions function instead of get_prediction\n",
    "def mesh_predictions(x, theta):\n",
    "    x = np.insert(x, 0, 1, axis=x.ndim-1)\n",
    "    theta = theta.reshape(-1,1)\n",
    "    y = x@theta\n",
    "    return y\n",
    "z_series = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a7dd306e8d61b2555f3a9bc6d0df2a8",
     "grade": true,
     "grade_id": "cell-9a816cae85d439af",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"xy_mesh.shape\", xy_mesh.shape)\n",
    "print(\"z_series.shape\", z_series.shape)\n",
    "#print(\"xy_mesh\", xy_mesh)\n",
    "#print(\"z_series\", z_series)\n",
    "\n",
    "# Test function: Do not remove\n",
    "assert xy_mesh.shape == (num_linspace, num_linspace, 2), \"mesh shape is incorrect\"\n",
    "assert z_series.shape == (num_linspace, num_linspace), \"z_series is incorrect\"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04aa24bda4554cc23bd5a738c05443f3",
     "grade": false,
     "grade_id": "cell-505cf4272cde5a84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect output**:\\\n",
    "xy_mesh.shape (100, 100, 2)\\\n",
    "z_series.shape (100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "362e25afc8ac64bcd2254ac4cf33cef5",
     "grade": false,
     "grade_id": "cell-ab8bef4203ed281f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2.6 (2 points)\n",
    "\n",
    "Plot **surface** of theta with the dataset points from xy_mesh and z_series above.\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\" color=\"green\"><b>Hint:</b></font></summary>\n",
    "You can use Axes3D.plot_surface in the link: https://matplotlib.org/2.0.2/mpl_toolkits/mplot3d/tutorial.html\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c13d6871744630c15ec9ffd8214f646",
     "grade": false,
     "grade_id": "cell-0473984307b36986",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "# 1. Set plot graph as 3D\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# 2. Extract data\n",
    "# extract year at x-axis\n",
    "# extract month at y-axis\n",
    "# extract sale amount at z-axis\n",
    "x_year = None\n",
    "y_month = None\n",
    "z_sale = None\n",
    "\n",
    "# 3. plot by using scatter\n",
    "# 4. set x, y, z label\n",
    "#    Hint: In these 3, 4 steps, you can copy Exercise 2.3\n",
    "# 5. Plot surface from x_mesh, y_mesh, and z_series\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c9cedd71cde961389e4539aa31a62cb",
     "grade": true,
     "grade_id": "cell-d89f019001f81ea1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test function: Do not remove\n",
    "assert ax.get_xbound()[1] >= 2014 and ax.get_xbound()[0] <= 1995, \"Year is filled wrong column\"\n",
    "assert ax.get_ybound()[1] >= 12 and ax.get_ybound()[0] <= 1, \"Month is filled wrong column\"\n",
    "assert ax.get_zbound()[1] >= 100000 and ax.get_zbound()[0] <= 0, \"Year is filled wrong column\"\n",
    "assert 'year' in ax.get_xlabel().lower(), \"x-axis label is incorrect\"\n",
    "assert 'month' in ax.get_ylabel().lower(), \"y-axis label is incorrect\"\n",
    "assert 'sale' in ax.get_zlabel().lower(), \"y-axis label is incorrect\"\n",
    "print(\"success\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2e6d8ba27c032409bed6480dae3aa84",
     "grade": false,
     "grade_id": "cell-ec03204b2cc9283a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expect result:**\n",
    "<img src=\"lab02-02.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "194e4336110883d16fc3c382345ddd47",
     "grade": false,
     "grade_id": "cell-1cff05f8209faa18",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Exercise 2.7 (20 points)\n",
    "\n",
    "Develop polynomial regression models of degree 2 and 3 based on the two input variables. Show results as 3D surface plots and discuss whether you observe overfitting or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = (data-np.mean(data, axis = 0))/np.std(data, axis = 0)\n",
    "y_label = 'sale amount';\n",
    "y_index = np.where(headers == y_label)[0][0];\n",
    "y = data_csv[:,y_index];                      \n",
    "X = data_csv[:,0:y_index];                 \n",
    "m = data_norm.shape[0]\n",
    "\n",
    "percent_train = .6\n",
    "random.shuffle(idx)\n",
    "    \n",
    "m_train = int(m * percent_train)\n",
    "train_idx = idx[0:m_train]\n",
    "test_idx = idx[m_train:m+1]\n",
    "\n",
    "X_train = data_csv[train_idx, 0:y_index];\n",
    "X_test = data_csv[test_idx, 0:y_index];\n",
    "y_train = data_csv[train_idx, y_index];\n",
    "y_test = data_csv[test_idx, y_index];\n",
    "\n",
    "#=============================\n",
    "\n",
    "# Polynomial regression model d=2, 3\n",
    "for i in range(2):\n",
    "    Xi_train = x_polynomial(X_train, i + 2)    \n",
    "    Xi_test = x_polynomial(X_test, i + 2)\n",
    "\n",
    "    theta = regression(Xi_train, y_train)\n",
    "    J_train = cost(theta, Xi_train, y_train)\n",
    "    y_pred_test = h(Xi_test, theta)\n",
    "    J_test = cost(theta, Xi_test, y_test)   \n",
    "\n",
    "    # 3D plot\n",
    "    print(\"3D plot: Polynomial degree 2\",\"\\n\")\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    x_year = data_csv[:, 0]\n",
    "    y_month = data_csv[:, 1]\n",
    "    z_sale = data_csv[:, 2]\n",
    "\n",
    "    # 3. plot by using scatter\n",
    "    p = ax.scatter(x_year,y_month, z_sale,edgecolors='black', c=data_norm[:,2],alpha=1)\n",
    "\n",
    "    # 4. set x, y, z label\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Month')\n",
    "    ax.set_zlabel('Sale')\n",
    "\n",
    "    # plot observation\n",
    "    x_series = np.linspace(min(data_csv[:,0]), max(data_csv[:,0]),len(y_csv))\n",
    "    y_series = np.linspace(min(data_csv[:,1]), max(data_csv[:,1]),len(y_csv))\n",
    "\n",
    "    x_mesh, y_mesh = np.meshgrid(x_series, y_series)\n",
    "    \n",
    "    if i == 0: # degree 2\n",
    "        yy =(theta[0] +theta[1]*x_mesh.T+theta[2]*y_mesh+theta[3]*(x_mesh*y_mesh)+theta[4]*(y_mesh**2+x_mesh**2))\n",
    "    else: # degree 3\n",
    "        yy=(theta[0]+theta[1]*(x_mesh+y_mesh).T+theta[2]*x_mesh*y_mesh +theta[3]*x_mesh**2+theta[4]*y_mesh**2+theta[5]* y_mesh*x_mesh**2+theta[6]*y_mesh**3)\n",
    "\n",
    "    p = ax.plot_surface(x_mesh, y_mesh,yy,alpha=0.5)\n",
    "    ax.view_init(elev=20, azim=10)\n",
    "    plt.colorbar(p)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a634a91a2aece7c5d0fbe2c3c54a4710",
     "grade": false,
     "grade_id": "cell-e7b8b113e71378d9",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Exercise 3 Take-home exercise (50 points)\n",
    "\n",
    "Using the dataset you played with for the take-home exercise in Lab 01, perform the same analysis. You won't be able to visualize the model well, as you will have more\n",
    "than two inputs, but try to give some idea of the performance of the model visually. Also, depending on the number of variables in your dataset, you may not be able to\n",
    "increase the polynomial degree beyond 2. Discuss whether the polynomial model is better than the linear model and whether you observe overfitting.\n",
    "\n",
    "### Write all code in youre new file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To turn in\n",
    "\n",
    "Before the next lab, turn in a brief report in the form of a Jupyter notebook documenting your work in the lab and the take-home exercise, along with your observations\n",
    "and discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
